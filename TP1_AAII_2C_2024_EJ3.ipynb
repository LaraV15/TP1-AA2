{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaraV15/TP1-AA2-GarciaValeri/blob/main/TP1_AAII_2C_2024_EJ3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftOarmdf-drj"
      },
      "source": [
        "# Lab 3a: MNIST\n",
        "\n",
        "El objetivo de este laboratorio es entrenar una red neuronal para clasificar dígitos escritos a mano. Para ello, utilizaremos el conjunto de datos MNIST, que contiene 70,000 imágenes de 28x28 píxeles en escala de grises de dígitos escritos a mano."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKBsi57n-dro"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FCEIA-AAII/lab2/blob/main/lab3a.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHZkCQIA-drp"
      },
      "source": [
        "## Preparación del entorno.\n",
        "\n",
        "Si no estamos parados en el repo, clonar y cd al repo. Esto nos permite usar el mismo notebook tanto local como en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2U0d2Jmd-drq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "REPO_NAME = \"TP1-AA2-GarciaValeri\"\n",
        "if REPO_NAME not in os.getcwd():\n",
        "  if not os.path.exists(REPO_NAME):\n",
        "    !git clone https://github.com/LaraV15/TP1-AA2-GarciaValeri.git\n",
        "  os.chdir(REPO_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPR4ywHG-drs"
      },
      "source": [
        "Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueoriea9-drs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jazH2cHD-drs"
      },
      "source": [
        "Establecer GPU por defecto en caso de estar disponible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqLweuLe-drt"
      },
      "outputs": [],
      "source": [
        "# Configurar para que TensorFlow utilice la GPU por defecto\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Configurar para que TensorFlow asigne memoria dinámicamente\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        # Especificar la GPU por defecto\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Manejar error\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96LwbmEj-drt"
      },
      "source": [
        "## Análisis Exploratorio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz7ZtAAt-drt"
      },
      "source": [
        "Cargar y visualizar los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkkd8f3s-drt"
      },
      "outputs": [],
      "source": [
        "# Cargamos MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalizamos los datos\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "print(\"Ejemplos de entrenamiento:\", X_train.shape)\n",
        "print(\"Ejemplos de test:\", X_test.shape)\n",
        "\n",
        "# Mostramos algunos ejemplos al azar:\n",
        "fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
        "for i in range(5):\n",
        "    idx = np.random.randint(0, X_train.shape[0])\n",
        "    axs[i].imshow(X_train[idx], cmap='gray')\n",
        "    axs[i].set_title(f\"Label: {y_train[idx]}\")\n",
        "    axs[i].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzHoeW1S-dru"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDbmPIyN-dru"
      },
      "source": [
        "Definimos nuestro modelo usando tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0k7BgZb--dru"
      },
      "outputs": [],
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "        # Flatten convierte la imagen 2D en un vector 1D de 28*28=784 componentes.\n",
        "        # Esto nos permite usar las imágenes directamente como entrada a la red.\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        ##### COMPLETAR DEFINICIÓN DE LA RED #####\n",
        "        # Agregar una capa oculta de entre 50 y 200 neuronas con función de activación a elección.\n",
        "        # Probar con distintas funciones de activación y cantidad de neuronas para obtener el mejor resultado.\n",
        "        # Agregar la capa de salida con la cantidad de neuronas y función de activación adecuadas.\n",
        "        ##########################################\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYHHDVXk-dru"
      },
      "source": [
        "Entrenamos el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEgg8n67-dru"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs6f9uQP-dru"
      },
      "source": [
        "Plot del historial de métricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lstNvS9-dru"
      },
      "outputs": [],
      "source": [
        "# Plot the training history, accuracy and loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0, 2])\n",
        "plt.legend(loc='upper right')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXxGQrmT-drv"
      },
      "source": [
        "Probamos predicciones sobre el conjunto de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHibNhmg-drv"
      },
      "outputs": [],
      "source": [
        "# Evaluamos el modelo sobre el conjunto de test\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "# Mostramos algunos ejemplos al azar:\n",
        "for i in range(5):\n",
        "    idx = np.random.randint(0, X_test.shape[0])\n",
        "    x_test = X_test[idx]\n",
        "    y_test_label = y_test[idx]\n",
        "    y_pred = Y_pred[idx]\n",
        "\n",
        "    # x_test es la imagen en escala de grises.\n",
        "    # y_test_label es la clase real.\n",
        "    # y_pred es un vector de probabilidades, mostramos la clase más probable\n",
        "\n",
        "    ##### COMPLETAR #####\n",
        "    # Obtener la clase predicha a partir de y_pred\n",
        "    # Mostrar un plot con la imagen x_test.\n",
        "    # Mostrar el título con la clase real y la clase predicha.\n",
        "    # Mostrar la probabilidad de la clase predicha.\n",
        "    ######################"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}